{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f807af2a",
   "metadata": {},
   "source": [
    "# Getting started with Text Preprocessing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "184117ca",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In any machine learning task, cleaning or preprocessing the data is as important as model building if not more. And when it comes to unstructured data like text, this process is even more important.\n",
    "\n",
    "Objective of this notebook is to understand the various text preprocessing steps with code examples.\n",
    "\n",
    "Some of the common text preprocessing / cleaning steps are:\n",
    "\n",
    "- Lower casing\n",
    "- Removal of Punctuations\n",
    "- Removal of Stopwords\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- Removal of emojis\n",
    "- Removal of emoticons\n",
    "- Conversion of emoticons to words\n",
    "- Conversion of emojis to words\n",
    "- Removal of URLs\n",
    "- Removal of HTML tags\n",
    "- Chat words conversion\n",
    "- Spelling correction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e881cf2c",
   "metadata": {},
   "source": [
    "So these are the different types of text preprocessing steps which we can do on text data. But we need not do all of these all the times. We need to carefully choose the preprocessing steps based on our use case since that also play an important role.\n",
    "\n",
    "For example, in sentiment analysis use case, we need not remove the emojis or emoticons as it will convey some important information about the sentiment. Similarly we need to decide based on our use cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8d77ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "import spacy\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7654d65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.read_csv(r\"C:\\Users\\HOME\\Desktop\\Hailabs Assignments\\NLP\\sample.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0743915e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>author_id</th>\n",
       "      <th>inbound</th>\n",
       "      <th>created_at</th>\n",
       "      <th>text</th>\n",
       "      <th>response_tweet_id</th>\n",
       "      <th>in_response_to_tweet_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>119237</td>\n",
       "      <td>105834</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 06:55:44 +0000 2017</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>119236</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>119238</td>\n",
       "      <td>ChaseSupport</td>\n",
       "      <td>False</td>\n",
       "      <td>Wed Oct 11 13:25:49 +0000 2017</td>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>119239.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>119239</td>\n",
       "      <td>105835</td>\n",
       "      <td>True</td>\n",
       "      <td>Wed Oct 11 13:00:09 +0000 2017</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>119238</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119240</td>\n",
       "      <td>VirginTrains</td>\n",
       "      <td>False</td>\n",
       "      <td>Tue Oct 10 15:16:08 +0000 2017</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>119241</td>\n",
       "      <td>119242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>119241</td>\n",
       "      <td>105836</td>\n",
       "      <td>True</td>\n",
       "      <td>Tue Oct 10 15:17:21 +0000 2017</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>119243</td>\n",
       "      <td>119240.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweet_id     author_id  inbound                      created_at  \\\n",
       "0    119237        105834     True  Wed Oct 11 06:55:44 +0000 2017   \n",
       "1    119238  ChaseSupport    False  Wed Oct 11 13:25:49 +0000 2017   \n",
       "2    119239        105835     True  Wed Oct 11 13:00:09 +0000 2017   \n",
       "3    119240  VirginTrains    False  Tue Oct 10 15:16:08 +0000 2017   \n",
       "4    119241        105836     True  Tue Oct 10 15:17:21 +0000 2017   \n",
       "\n",
       "                                                text response_tweet_id  \\\n",
       "0  @AppleSupport causing the reply to be disregar...            119236   \n",
       "1  @105835 Your business means a lot to us. Pleas...               NaN   \n",
       "2  @76328 I really hope you all change but I'm su...            119238   \n",
       "3  @105836 LiveChat is online at the moment - htt...            119241   \n",
       "4  @VirginTrains see attached error message. I've...            119243   \n",
       "\n",
       "   in_response_to_tweet_id  \n",
       "0                      NaN  \n",
       "1                 119239.0  \n",
       "2                      NaN  \n",
       "3                 119242.0  \n",
       "4                 119240.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "af1e57a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = full_df[[\"text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f2b41ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>@105860 I wish Amazon had an option of where I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>They reschedule my shit for tomorrow https://t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>@105861 Hey Sara, sorry to hear of the issues ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>@Tesco bit of both - finding the layout cumber...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>@105861 If that doesn't help please DM your fu...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>93 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text\n",
       "0   @AppleSupport causing the reply to be disregar...\n",
       "1   @105835 Your business means a lot to us. Pleas...\n",
       "2   @76328 I really hope you all change but I'm su...\n",
       "3   @105836 LiveChat is online at the moment - htt...\n",
       "4   @VirginTrains see attached error message. I've...\n",
       "..                                                ...\n",
       "88  @105860 I wish Amazon had an option of where I...\n",
       "89  They reschedule my shit for tomorrow https://t...\n",
       "90  @105861 Hey Sara, sorry to hear of the issues ...\n",
       "91  @Tesco bit of both - finding the layout cumber...\n",
       "92  @105861 If that doesn't help please DM your fu...\n",
       "\n",
       "[93 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c8b6b0",
   "metadata": {},
   "source": [
    "## 1. Lower Casing\n",
    "\n",
    "Lower casing is a common text preprocessing technique. The idea is to convert the input text into same casing format so that 'text', 'Text' and 'TEXT' are treated the same way.\n",
    "\n",
    "This is more helpful for text featurization techniques like frequency, tfidf as it helps to combine the same words together thereby reducing the duplication and get correct counts / tfidf values.\n",
    "\n",
    "This may not be helpful when we do tasks like Part of Speech tagging (where proper casing gives some information about Nouns and so on) and Sentiment Analysis (where upper casing refers to anger and so on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7da6f810",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-a4d14cd694ba>:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_lower\"] = df[\"text\"].str.lower()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport causing the reply to be disregar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your business means a lot to us. pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i really hope you all change but i'm su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is online at the moment - htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrains see attached error message. i've...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                          text_lower  \n",
       "0  @applesupport causing the reply to be disregar...  \n",
       "1  @105835 your business means a lot to us. pleas...  \n",
       "2  @76328 i really hope you all change but i'm su...  \n",
       "3  @105836 livechat is online at the moment - htt...  \n",
       "4  @virgintrains see attached error message. i've...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"text_lower\"] = df[\"text\"].str.lower()\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a11cf2",
   "metadata": {},
   "source": [
    "## 2. Removal of Punctuations\n",
    "\n",
    "One another common text preprocessing technique is to remove the punctuations from the text data. This is again a text standardization process that will help to treat 'hurray' and 'hurray!' in the same way.\n",
    "\n",
    "We also need to carefully choose the list of punctuations to exclude depending on the use case. For example, the string.punctuation in python contains the following punctuation symbols\n",
    "\n",
    "!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_{|}~`\n",
    "\n",
    "We can add or remove more punctuations as per our need.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c985a03e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-7-77e4cae6dba1>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_wo_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n"
     ]
    }
   ],
   "source": [
    "PUNCT_TO_REMOVE = string.punctuation\n",
    "\n",
    "def remove_punctuation(text):\n",
    "\n",
    "    return text.translate(str.maketrans('', '', PUNCT_TO_REMOVE))\n",
    "\n",
    "df[\"text_wo_punct\"] = df[\"text\"].apply(lambda text: remove_punctuation(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cca979e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport causing the reply to be disregar...</td>\n",
       "      <td>AppleSupport causing the reply to be disregard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your business means a lot to us. pleas...</td>\n",
       "      <td>105835 Your business means a lot to us Please ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i really hope you all change but i'm su...</td>\n",
       "      <td>76328 I really hope you all change but Im sure...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is online at the moment - htt...</td>\n",
       "      <td>105836 LiveChat is online at the moment  https...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrains see attached error message. i've...</td>\n",
       "      <td>VirginTrains see attached error message Ive tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @applesupport causing the reply to be disregar...   \n",
       "1  @105835 your business means a lot to us. pleas...   \n",
       "2  @76328 i really hope you all change but i'm su...   \n",
       "3  @105836 livechat is online at the moment - htt...   \n",
       "4  @virgintrains see attached error message. i've...   \n",
       "\n",
       "                                       text_wo_punct  \n",
       "0  AppleSupport causing the reply to be disregard...  \n",
       "1  105835 Your business means a lot to us Please ...  \n",
       "2  76328 I really hope you all change but Im sure...  \n",
       "3  105836 LiveChat is online at the moment  https...  \n",
       "4  VirginTrains see attached error message Ive tr...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02c7d96",
   "metadata": {},
   "source": [
    "## 3. Removal of stopwords\n",
    "\n",
    "Stopwords are commonly occuring words in a language like 'the', 'a' and so on. They can be removed from the text most of the times, as they don't provide valuable information for downstream analysis. In cases like Part of Speech tagging, we should not remove them as provide very valuable information about the POS.\n",
    "\n",
    "These stopword lists are already compiled for different languages and we can safely use them. For example, the stopword list for english language from the nltk package can be seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "853bfd4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"i, me, my, myself, we, our, ours, ourselves, you, you're, you've, you'll, you'd, your, yours, yourself, yourselves, he, him, his, himself, she, she's, her, hers, herself, it, it's, its, itself, they, them, their, theirs, themselves, what, which, who, whom, this, that, that'll, these, those, am, is, are, was, were, be, been, being, have, has, had, having, do, does, did, doing, a, an, the, and, but, if, or, because, as, until, while, of, at, by, for, with, about, against, between, into, through, during, before, after, above, below, to, from, up, down, in, out, on, off, over, under, again, further, then, once, here, there, when, where, why, how, all, any, both, each, few, more, most, other, some, such, no, nor, not, only, own, same, so, than, too, very, s, t, can, will, just, don, don't, should, should've, now, d, ll, m, o, re, ve, y, ain, aren, aren't, couldn, couldn't, didn, didn't, doesn, doesn't, hadn, hadn't, hasn, hasn't, haven, haven't, isn, isn't, ma, mightn, mightn't, mustn, mustn't, needn, needn't, shan, shan't, shouldn, shouldn't, wasn, wasn't, weren, weren't, won, won't, wouldn, wouldn't\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\", \".join(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da62aa91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-4659ee008caa>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n"
     ]
    }
   ],
   "source": [
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    \n",
    "    return \" \".join([word for word in str(text).split() if word not in STOPWORDS])\n",
    "\n",
    "df[\"text_wo_stop\"] = df[\"text_wo_punct\"].apply(lambda text: remove_stopwords(text))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff7da0e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_lower</th>\n",
       "      <th>text_wo_punct</th>\n",
       "      <th>text_wo_stop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport causing the reply to be disregar...</td>\n",
       "      <td>AppleSupport causing the reply to be disregard...</td>\n",
       "      <td>AppleSupport causing reply disregarded tapped ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your business means a lot to us. pleas...</td>\n",
       "      <td>105835 Your business means a lot to us Please ...</td>\n",
       "      <td>105835 Your business means lot us Please DM na...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i really hope you all change but i'm su...</td>\n",
       "      <td>76328 I really hope you all change but Im sure...</td>\n",
       "      <td>76328 I really hope change Im sure wont Becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is online at the moment - htt...</td>\n",
       "      <td>105836 LiveChat is online at the moment  https...</td>\n",
       "      <td>105836 LiveChat online moment httpstcoSY94VtU8...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrains see attached error message. i've...</td>\n",
       "      <td>VirginTrains see attached error message Ive tr...</td>\n",
       "      <td>VirginTrains see attached error message Ive tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                          text_lower  \\\n",
       "0  @applesupport causing the reply to be disregar...   \n",
       "1  @105835 your business means a lot to us. pleas...   \n",
       "2  @76328 i really hope you all change but i'm su...   \n",
       "3  @105836 livechat is online at the moment - htt...   \n",
       "4  @virgintrains see attached error message. i've...   \n",
       "\n",
       "                                       text_wo_punct  \\\n",
       "0  AppleSupport causing the reply to be disregard...   \n",
       "1  105835 Your business means a lot to us Please ...   \n",
       "2  76328 I really hope you all change but Im sure...   \n",
       "3  105836 LiveChat is online at the moment  https...   \n",
       "4  VirginTrains see attached error message Ive tr...   \n",
       "\n",
       "                                        text_wo_stop  \n",
       "0  AppleSupport causing reply disregarded tapped ...  \n",
       "1  105835 Your business means lot us Please DM na...  \n",
       "2  76328 I really hope change Im sure wont Becaus...  \n",
       "3  105836 LiveChat online moment httpstcoSY94VtU8...  \n",
       "4  VirginTrains see attached error message Ive tr...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6e69f614",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4308: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    }
   ],
   "source": [
    "df.drop([\"text_lower\", \"text_wo_punct\",\"text_wo_stop\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f32b7641",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  @AppleSupport causing the reply to be disregar...\n",
       "1  @105835 Your business means a lot to us. Pleas...\n",
       "2  @76328 I really hope you all change but I'm su...\n",
       "3  @105836 LiveChat is online at the moment - htt...\n",
       "4  @VirginTrains see attached error message. I've..."
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96c69c0",
   "metadata": {},
   "source": [
    "## 4.Stemming\n",
    "\n",
    "Stemming is the process of reducing inflected (or sometimes derived) words to their word stem, base or root form (From Wikipedia)\n",
    "\n",
    "For example, if there are two words in the corpus walks and walking, then stemming will stem the suffix to make them walk. But say in another example, we have two words console and consoling, the stemmer will remove the suffix and make them consol which is not a proper english word.\n",
    "\n",
    "There are several type of stemming algorithms available and one of the famous one is porter stemmer which is widely used. We can use nltk package for the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef54889e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem.porter import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2748543c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-16-92060573db81>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))\n"
     ]
    }
   ],
   "source": [
    "stemmer = PorterStemmer()\n",
    "\n",
    "def stem_words(text):\n",
    "    \n",
    "    return \" \".join([stemmer.stem(word) for word in text.split()])\n",
    "\n",
    "df[\"text_stemmed\"] = df[\"text\"].apply(lambda text: stem_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc183301",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport caus the repli to be disregard a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your busi mean a lot to us. pleas dm y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i realli hope you all chang but i'm sur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is onlin at the moment - http...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrain see attach error message. i'v tri...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                        text_stemmed  \n",
       "0  @applesupport caus the repli to be disregard a...  \n",
       "1  @105835 your busi mean a lot to us. pleas dm y...  \n",
       "2  @76328 i realli hope you all chang but i'm sur...  \n",
       "3  @105836 livechat is onlin at the moment - http...  \n",
       "4  @virgintrain see attach error message. i'v tri...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1978b30",
   "metadata": {},
   "source": [
    "Also this porter stemmer is for English language. If we are working with other languages, we can use snowball stemmer. The supported languages for snowball stemmer are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ed43a28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('arabic',\n",
       " 'danish',\n",
       " 'dutch',\n",
       " 'english',\n",
       " 'finnish',\n",
       " 'french',\n",
       " 'german',\n",
       " 'hungarian',\n",
       " 'italian',\n",
       " 'norwegian',\n",
       " 'porter',\n",
       " 'portuguese',\n",
       " 'romanian',\n",
       " 'russian',\n",
       " 'spanish',\n",
       " 'swedish')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem.snowball import SnowballStemmer\n",
    "SnowballStemmer.languages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6066e6a",
   "metadata": {},
   "source": [
    "## 5. Lemmatization\n",
    "\n",
    "Lemmatization is similar to stemming in reducing inflected words to their word stem but differs in the way that it makes sure the root word (also called as lemma) belongs to the language.\n",
    "\n",
    "As a result, this one is generally slower than stemming process. So depending on the speed requirement, we can choose to use either stemming or lemmatization.\n",
    "\n",
    "Let us use the WordNetLemmatizer in nltk to lemmatize our sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4bdc81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2100880f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-20-a128ea020766>:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    \n",
    "    return \" \".join([lemmatizer.lemmatize(word) for word in text.split()])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5976e25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport caus the repli to be disregard a...</td>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your busi mean a lot to us. pleas dm y...</td>\n",
       "      <td>@105835 Your business mean a lot to us. Please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i realli hope you all chang but i'm sur...</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is onlin at the moment - http...</td>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrain see attach error message. i'v tri...</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  @applesupport caus the repli to be disregard a...   \n",
       "1  @105835 your busi mean a lot to us. pleas dm y...   \n",
       "2  @76328 i realli hope you all chang but i'm sur...   \n",
       "3  @105836 livechat is onlin at the moment - http...   \n",
       "4  @virgintrain see attach error message. i'v tri...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @AppleSupport causing the reply to be disregar...  \n",
       "1  @105835 Your business mean a lot to us. Please...  \n",
       "2  @76328 I really hope you all change but I'm su...  \n",
       "3  @105836 LiveChat is online at the moment - htt...  \n",
       "4  @VirginTrains see attached error message. I've...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4cef2b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'running'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"running\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7849b0d",
   "metadata": {},
   "source": [
    "Wow. It returned running as such without converting it to the root form run. This is because the lemmatization process depends on the POS tag to come up with the correct lemma. Now let us lemmatize again by providing the POS tag for the word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f7f2419",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'run'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"running\", \"v\")  # v for verb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf2db47",
   "metadata": {},
   "source": [
    "Now we are getting the root form run. So we also need to provide the POS tag of the word along with the word for lemmatizer in nltk. Depending on the POS, the lemmatizer may return different results.\n",
    "\n",
    "Let us take the example, stripes and check the lemma when it is both verb and noun"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "35b92cc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word is : stripes\n",
      "Lemma result for verb :  strip\n",
      "Lemma result for noun :  stripe\n"
     ]
    }
   ],
   "source": [
    "print(\"Word is : stripes\")\n",
    "\n",
    "print(\"Lemma result for verb : \",lemmatizer.lemmatize(\"stripes\", 'v'))\n",
    "print(\"Lemma result for noun : \",lemmatizer.lemmatize(\"stripes\", 'n'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "578c1c4c",
   "metadata": {},
   "source": [
    "Now let us redo the lemmatization process for our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "27ca0d7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ec1b923",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\HOME\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "319203ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-28-09602aed1774>:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))\n"
     ]
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "wordnet_map = {\"N\":wordnet.NOUN, \"V\":wordnet.VERB, \"J\":wordnet.ADJ, \"R\":wordnet.ADV}\n",
    "\n",
    "def lemmatize_words(text):\n",
    "    \n",
    "    pos_tagged_text = nltk.pos_tag(text.split())\n",
    "    return \" \".join([lemmatizer.lemmatize(word, wordnet_map.get(pos[0], wordnet.NOUN)) for word, pos in pos_tagged_text])\n",
    "\n",
    "df[\"text_lemmatized\"] = df[\"text\"].apply(lambda text: lemmatize_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ddca4869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>text_stemmed</th>\n",
       "      <th>text_lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@AppleSupport causing the reply to be disregar...</td>\n",
       "      <td>@applesupport caus the repli to be disregard a...</td>\n",
       "      <td>@AppleSupport cause the reply to be disregard ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>@105835 Your business means a lot to us. Pleas...</td>\n",
       "      <td>@105835 your busi mean a lot to us. pleas dm y...</td>\n",
       "      <td>@105835 Your business mean a lot to us. Please...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "      <td>@76328 i realli hope you all chang but i'm sur...</td>\n",
       "      <td>@76328 I really hope you all change but I'm su...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@105836 LiveChat is online at the moment - htt...</td>\n",
       "      <td>@105836 livechat is onlin at the moment - http...</td>\n",
       "      <td>@105836 LiveChat be online at the moment - htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "      <td>@virgintrain see attach error message. i'v tri...</td>\n",
       "      <td>@VirginTrains see attached error message. I've...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  @AppleSupport causing the reply to be disregar...   \n",
       "1  @105835 Your business means a lot to us. Pleas...   \n",
       "2  @76328 I really hope you all change but I'm su...   \n",
       "3  @105836 LiveChat is online at the moment - htt...   \n",
       "4  @VirginTrains see attached error message. I've...   \n",
       "\n",
       "                                        text_stemmed  \\\n",
       "0  @applesupport caus the repli to be disregard a...   \n",
       "1  @105835 your busi mean a lot to us. pleas dm y...   \n",
       "2  @76328 i realli hope you all chang but i'm sur...   \n",
       "3  @105836 livechat is onlin at the moment - http...   \n",
       "4  @virgintrain see attach error message. i'v tri...   \n",
       "\n",
       "                                     text_lemmatized  \n",
       "0  @AppleSupport cause the reply to be disregard ...  \n",
       "1  @105835 Your business mean a lot to us. Please...  \n",
       "2  @76328 I really hope you all change but I'm su...  \n",
       "3  @105836 LiveChat be online at the moment - htt...  \n",
       "4  @VirginTrains see attached error message. I've...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a48a744",
   "metadata": {},
   "source": [
    "## 6. Removal of Emojis\n",
    "\n",
    "With more and more usage of social media platforms, there is an explosion in the usage of emojis in our day to day life as well. Probably we might need to remove these emojis for some of our textual analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "47ac5b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'game is on '"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reference : https://gist.github.com/slowkow/7a7f61f495e3dbb7e3d767f97bd7304b\n",
    "\n",
    "def remove_emoji(string):\n",
    "    emoji_pattern = re.compile(\"[\"\n",
    "                           u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "                           u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "                           u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "                           u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           u\"\\U00002702-\\U000027B0\"\n",
    "                           u\"\\U000024C2-\\U0001F251\"\n",
    "                           \"]+\", flags=re.UNICODE)\n",
    "    return emoji_pattern.sub(r'', string)\n",
    "\n",
    "remove_emoji(\"game is on ðŸ”¥ðŸ”¥\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f05a443",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hilarious'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoji(\"HilariousðŸ˜‚\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e135e43f",
   "metadata": {},
   "source": [
    "## Removal of Emoticons\n",
    "\n",
    "This is what we did in the last step right? Nope. We did remove emojis in the last step but not emoticons. There is a minor difference between emojis and emoticons.\n",
    "\n",
    "From Grammarist.com, emoticon is built from keyboard characters that when put together in a certain way represent a facial expression, an emoji is an actual image.\n",
    "\n",
    ":-) is an emoticon\n",
    "\n",
    "ðŸ˜€ is an emoji\n",
    "\n",
    "Thanks to NeelShah for the wonderful collection of emoticons, we are going to use them to remove emoticons.\n",
    "\n",
    "Please note again that the removal of emojis / emoticons are not always preferred and decision should be made based on the use case at hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8dead4d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thanks : https://github.com/NeelShah18/emot/blob/master/emot/emo_unicode.py\n",
    "EMOTICONS = {\n",
    "    u\":â€‘\\)\":\"Happy face or smiley\",\n",
    "    u\":\\)\":\"Happy face or smiley\",\n",
    "    u\":-\\]\":\"Happy face or smiley\",\n",
    "    u\":\\]\":\"Happy face or smiley\",\n",
    "    u\":-3\":\"Happy face smiley\",\n",
    "    u\":3\":\"Happy face smiley\",\n",
    "    u\":->\":\"Happy face smiley\",\n",
    "    u\":>\":\"Happy face smiley\",\n",
    "    u\"8-\\)\":\"Happy face smiley\",\n",
    "    u\":o\\)\":\"Happy face smiley\",\n",
    "    u\":-\\}\":\"Happy face smiley\",\n",
    "    u\":\\}\":\"Happy face smiley\",\n",
    "    u\":-\\)\":\"Happy face smiley\",\n",
    "    u\":c\\)\":\"Happy face smiley\",\n",
    "    u\":\\^\\)\":\"Happy face smiley\",\n",
    "    u\"=\\]\":\"Happy face smiley\",\n",
    "    u\"=\\)\":\"Happy face smiley\",\n",
    "    u\":â€‘D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8â€‘D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"8D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"Xâ€‘D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"XD\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"=3\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\"B\\^D\":\"Laughing, big grin or laugh with glasses\",\n",
    "    u\":-\\)\\)\":\"Very happy\",\n",
    "    u\":â€‘\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":â€‘c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":c\":\"Frown, sad, andry or pouting\",\n",
    "    u\":â€‘<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":<\":\"Frown, sad, andry or pouting\",\n",
    "    u\":â€‘\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":-\\|\\|\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\[\":\"Frown, sad, andry or pouting\",\n",
    "    u\":\\{\":\"Frown, sad, andry or pouting\",\n",
    "    u\":@\":\"Frown, sad, andry or pouting\",\n",
    "    u\">:\\(\":\"Frown, sad, andry or pouting\",\n",
    "    u\":'â€‘\\(\":\"Crying\",\n",
    "    u\":'\\(\":\"Crying\",\n",
    "    u\":'â€‘\\)\":\"Tears of happiness\",\n",
    "    u\":'\\)\":\"Tears of happiness\",\n",
    "    u\"Dâ€‘':\":\"Horror\",\n",
    "    u\"D:<\":\"Disgust\",\n",
    "    u\"D:\":\"Sadness\",\n",
    "    u\"D8\":\"Great dismay\",\n",
    "    u\"D;\":\"Great dismay\",\n",
    "    u\"D=\":\"Great dismay\",\n",
    "    u\"DX\":\"Great dismay\",\n",
    "    u\":â€‘O\":\"Surprise\",\n",
    "    u\":O\":\"Surprise\",\n",
    "    u\":â€‘o\":\"Surprise\",\n",
    "    u\":o\":\"Surprise\",\n",
    "    u\":-0\":\"Shock\",\n",
    "    u\"8â€‘0\":\"Yawn\",\n",
    "    u\">:O\":\"Yawn\",\n",
    "    u\":-\\*\":\"Kiss\",\n",
    "    u\":\\*\":\"Kiss\",\n",
    "    u\":X\":\"Kiss\",\n",
    "    u\";â€‘\\)\":\"Wink or smirk\",\n",
    "    u\";\\)\":\"Wink or smirk\",\n",
    "    u\"\\*-\\)\":\"Wink or smirk\",\n",
    "    u\"\\*\\)\":\"Wink or smirk\",\n",
    "    u\";â€‘\\]\":\"Wink or smirk\",\n",
    "    u\";\\]\":\"Wink or smirk\",\n",
    "    u\";\\^\\)\":\"Wink or smirk\",\n",
    "    u\":â€‘,\":\"Wink or smirk\",\n",
    "    u\";D\":\"Wink or smirk\",\n",
    "    u\":â€‘P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"Xâ€‘P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"XP\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":â€‘Ãž\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":Ãž\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"d:\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"=p\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\">:P\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\":â€‘/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":-[.]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\">:/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=/\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=[(\\\\\\)]\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\"=L\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":S\":\"Skeptical, annoyed, undecided, uneasy or hesitant\",\n",
    "    u\":â€‘\\|\":\"Straight face\",\n",
    "    u\":\\|\":\"Straight face\",\n",
    "    u\":$\":\"Embarrassed or blushing\",\n",
    "    u\":â€‘x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":x\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":â€‘#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":#\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":â€‘&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\":&\":\"Sealed lips or wearing braces or tongue-tied\",\n",
    "    u\"O:â€‘\\)\":\"Angel, saint or innocent\",\n",
    "    u\"O:\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:â€‘3\":\"Angel, saint or innocent\",\n",
    "    u\"0:3\":\"Angel, saint or innocent\",\n",
    "    u\"0:â€‘\\)\":\"Angel, saint or innocent\",\n",
    "    u\"0:\\)\":\"Angel, saint or innocent\",\n",
    "    u\":â€‘b\":\"Tongue sticking out, cheeky, playful or blowing a raspberry\",\n",
    "    u\"0;\\^\\)\":\"Angel, saint or innocent\",\n",
    "    u\">:â€‘\\)\":\"Evil or devilish\",\n",
    "    u\">:\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:â€‘\\)\":\"Evil or devilish\",\n",
    "    u\"\\}:\\)\":\"Evil or devilish\",\n",
    "    u\"3:â€‘\\)\":\"Evil or devilish\",\n",
    "    u\"3:\\)\":\"Evil or devilish\",\n",
    "    u\">;\\)\":\"Evil or devilish\",\n",
    "    u\"\\|;â€‘\\)\":\"Cool\",\n",
    "    u\"\\|â€‘O\":\"Bored\",\n",
    "    u\":â€‘J\":\"Tongue-in-cheek\",\n",
    "    u\"#â€‘\\)\":\"Party all night\",\n",
    "    u\"%â€‘\\)\":\"Drunk or confused\",\n",
    "    u\"%\\)\":\"Drunk or confused\",\n",
    "    u\":-###..\":\"Being sick\",\n",
    "    u\":###..\":\"Being sick\",\n",
    "    u\"<:â€‘\\|\":\"Dump\",\n",
    "    u\"\\(>_<\\)\":\"Troubled\",\n",
    "    u\"\\(>_<\\)>\":\"Troubled\",\n",
    "    u\"\\(';'\\)\":\"Baby\",\n",
    "    u\"\\(\\^\\^>``\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(\\^_\\^;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(~_~;\\) \\(ãƒ»\\.ãƒ»;\\)\":\"Nervous or Embarrassed or Troubled or Shy or Sweat drop\",\n",
    "    u\"\\(-_-\\)zzz\":\"Sleeping\",\n",
    "    u\"\\(\\^_-\\)\":\"Wink\",\n",
    "    u\"\\(\\(\\+_\\+\\)\\)\":\"Confused\",\n",
    "    u\"\\(\\+o\\+\\)\":\"Confused\",\n",
    "    u\"\\(o\\|o\\)\":\"Ultraman\",\n",
    "    u\"\\^_\\^\":\"Joyful\",\n",
    "    u\"\\(\\^_\\^\\)/\":\"Joyful\",\n",
    "    u\"\\(\\^O\\^\\)ï¼\":\"Joyful\",\n",
    "    u\"\\(\\^o\\^\\)ï¼\":\"Joyful\",\n",
    "    u\"\\(__\\)\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"_\\(\\._\\.\\)_\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<\\(_ _\\)>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"<m\\(__\\)m>\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(__\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"m\\(_ _\\)m\":\"Kowtow as a sign of respect, or dogeza for apology\",\n",
    "    u\"\\('_'\\)\":\"Sad or Crying\",\n",
    "    u\"\\(/_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(T_T\\) \\(;_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;_;\":\"Sad of Crying\",\n",
    "    u\"\\(;_:\\)\":\"Sad or Crying\",\n",
    "    u\"\\(;O;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(:_;\\)\":\"Sad or Crying\",\n",
    "    u\"\\(ToT\\)\":\"Sad or Crying\",\n",
    "    u\";_;\":\"Sad or Crying\",\n",
    "    u\";-;\":\"Sad or Crying\",\n",
    "    u\";n;\":\"Sad or Crying\",\n",
    "    u\";;\":\"Sad or Crying\",\n",
    "    u\"Q\\.Q\":\"Sad or Crying\",\n",
    "    u\"T\\.T\":\"Sad or Crying\",\n",
    "    u\"QQ\":\"Sad or Crying\",\n",
    "    u\"Q_Q\":\"Sad or Crying\",\n",
    "    u\"\\(-\\.-\\)\":\"Shame\",\n",
    "    u\"\\(-_-\\)\":\"Shame\",\n",
    "    u\"\\(ä¸€ä¸€\\)\":\"Shame\",\n",
    "    u\"\\(ï¼›ä¸€_ä¸€\\)\":\"Shame\",\n",
    "    u\"\\(=_=\\)\":\"Tired\",\n",
    "    u\"\\(=\\^\\Â·\\^=\\)\":\"cat\",\n",
    "    u\"\\(=\\^\\Â·\\Â·\\^=\\)\":\"cat\",\n",
    "    u\"=_\\^=\t\":\"cat\",\n",
    "    u\"\\(\\.\\.\\)\":\"Looking down\",\n",
    "    u\"\\(\\._\\.\\)\":\"Looking down\",\n",
    "    u\"\\^m\\^\":\"Giggling with hand covering mouth\",\n",
    "    u\"\\(\\ãƒ»\\ãƒ»?\":\"Confusion\",\n",
    "    u\"\\(?_?\\)\":\"Confusion\",\n",
    "    u\">\\^_\\^<\":\"Normal Laugh\",\n",
    "    u\"<\\^!\\^>\":\"Normal Laugh\",\n",
    "    u\"\\^/\\^\":\"Normal Laugh\",\n",
    "    u\"\\ï¼ˆ\\*\\^_\\^\\*ï¼‰\" :\"Normal Laugh\",\n",
    "    u\"\\(\\^<\\^\\) \\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\.\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\.\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^_\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^J\\^\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\*\\^\\.\\^\\*\\)\":\"Normal Laugh\",\n",
    "    u\"\\(\\^â€”\\^\\ï¼‰\":\"Normal Laugh\",\n",
    "    u\"\\(#\\^\\.\\^#\\)\":\"Normal Laugh\",\n",
    "    u\"\\ï¼ˆ\\^â€”\\^\\ï¼‰\":\"Waving\",\n",
    "    u\"\\(;_;\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\^\\.\\^\\)/~~~\":\"Waving\",\n",
    "    u\"\\(-_-\\)/~~~ \\($\\Â·\\Â·\\)/~~~\":\"Waving\",\n",
    "    u\"\\(T_T\\)/~~~\":\"Waving\",\n",
    "    u\"\\(ToT\\)/~~~\":\"Waving\",\n",
    "    u\"\\(\\*\\^0\\^\\*\\)\":\"Excited\",\n",
    "    u\"\\(\\*_\\*\\)\":\"Amazed\",\n",
    "    u\"\\(\\*_\\*;\":\"Amazed\",\n",
    "    u\"\\(\\+_\\+\\) \\(@_@\\)\":\"Amazed\",\n",
    "    u\"\\(\\*\\^\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\^_\\^\\)v\":\"Laughing,Cheerful\",\n",
    "    u\"\\(\\(d[-_-]b\\)\\)\":\"Headphones,Listening to music\",\n",
    "    u'\\(-\"-\\)':\"Worried\",\n",
    "    u\"\\(ãƒ¼ãƒ¼;\\)\":\"Worried\",\n",
    "    u\"\\(\\^0_0\\^\\)\":\"Eyeglasses\",\n",
    "    u\"\\(\\ï¼¾ï½–\\ï¼¾\\)\":\"Happy\",\n",
    "    u\"\\(\\ï¼¾ï½•\\ï¼¾\\)\":\"Happy\",\n",
    "    u\"\\(\\^\\)o\\(\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^O\\^\\)\":\"Happy\",\n",
    "    u\"\\(\\^o\\^\\)\":\"Happy\",\n",
    "    u\"\\)\\^o\\^\\(\":\"Happy\",\n",
    "    u\":O o_O\":\"Surprised\",\n",
    "    u\"o_0\":\"Surprised\",\n",
    "    u\"o\\.O\":\"Surpised\",\n",
    "    u\"\\(o\\.o\\)\":\"Surprised\",\n",
    "    u\"oO\":\"Surprised\",\n",
    "    u\"\\(\\*ï¿£mï¿£\\)\":\"Dissatisfied\",\n",
    "    u\"\\(â€˜A`\\)\":\"Snubbed or Deflated\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d68108c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello '"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_emoticons(text):\n",
    "    \n",
    "    emoticon_pattern = re.compile(u'(' + u'|'.join(k for k in EMOTICONS) + u')')\n",
    "    return emoticon_pattern.sub(r'', text)\n",
    "\n",
    "remove_emoticons(\"Hello :-)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d6f196ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sad '"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_emoticons(\"I am sad :(\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0340c0e",
   "metadata": {},
   "source": [
    "## 7. Conversion of Emoticon to Words\n",
    "\n",
    "In the previous step, we have removed the emoticons. In case of use cases like sentiment analysis, the emoticons give some valuable information and so removing them might not be a good solution. What can we do in such cases?\n",
    "\n",
    "One way is to convert the emoticons to word format so that they can be used in downstream modeling processes. Thanks for Neel again for the wonderful dictionary that we have used in the previous step. We are going to use that again for conversion of emoticons to words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87920c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_emoticons(text):\n",
    "    for emot in EMOTICONS:\n",
    "        text = re.sub(u'('+emot+')', \"_\".join(EMOTICONS[emot].replace(\",\",\"\").split()), text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6c213366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello Happy_face_smiley Happy_face_smiley'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Hello :-) :-)\"\n",
    "\n",
    "convert_emoticons(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "269a756b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I am sad Frown_sad_andry_or_poutingConfusion'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"I am sad :()\"\n",
    "\n",
    "convert_emoticons(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b244e0a1",
   "metadata": {},
   "source": [
    "## 8. Removal of URLs\n",
    "\n",
    "Next preprocessing step is to remove any URLs present in the data. For example, if we are doing a twitter analysis, then there is a good chance that the tweet will have some URL in it. Probably we might need to remove them for our further analysis.\n",
    "\n",
    "We can use the below code snippet to do that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc7f9f7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_urls(text):\n",
    "    \n",
    "    url_pattern = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url_pattern.sub(r'', text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3460620d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Driverless AI NLP blog post on '"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Driverless AI NLP blog post on https://www.h2o.ai/blog/detecting-sarcasm-is-difficult-but-ai-may-have-an-answer/\"\n",
    "\n",
    "remove_urls(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1b6d6e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Please refer to link  for the paper'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Please refer to link http://lnkd.in/ecnt5yC for the paper\"\n",
    "\n",
    "remove_urls(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8944d7ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Want to know more. Checkout  for additional information'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"Want to know more. Checkout www.h2o.ai for additional information\"\n",
    "\n",
    "remove_urls(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbb22d2",
   "metadata": {},
   "source": [
    "## 9. Removal of HTML Tags\n",
    "\n",
    "One another common preprocessing technique that will come handy in multiple places is removal of html tags. This is especially useful, if we scrap the data from different websites. We might end up having html strings as part of our text.\n",
    "\n",
    "First, let us try to remove the HTML tags using regular expressions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "316e0f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "text = \"\"\"<div>\n",
    "<h1> H2O</h1>\n",
    "<p> AutoML</p>\n",
    "<a href=\"https://www.h2o.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n",
    "</div>\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "90df7cc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " H2O\n",
      " AutoML\n",
      " Driverless AI\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_html(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfbce670",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def remove_html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").text\n",
    "\n",
    "text = \"\"\"<div>\n",
    "<h1> H2O</h1>\n",
    "<p> AutoML</p>\n",
    "<a href=\"https://www.h2o.ai/products/h2o-driverless-ai/\"> Driverless AI</a>\n",
    "</div>\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "55480772",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " H2O\n",
      " AutoML\n",
      " Driverless AI\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(remove_html(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16efeb9b",
   "metadata": {},
   "source": [
    "## 9. Chat Words Conversion\n",
    "\n",
    "This is an important text preprocessing step if we are dealing with chat data. People do use a lot of abbreviated words in chat and so it might be helpful to expand those words for our analysis purposes.\n",
    "\n",
    "Got a good list of chat slang words from this repo. We can use this for our conversion here. We can add more words to this list.\n",
    "\n",
    "repo link : https://github.com/rishabhverma17/sms_slang_translator/blob/master/slang.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "311f66a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_str = \"\"\"\n",
    "AFAIK=As Far As I Know\n",
    "AFK=Away From Keyboard\n",
    "ASAP=As Soon As Possible\n",
    "ATK=At The Keyboard\n",
    "ATM=At The Moment\n",
    "A3=Anytime, Anywhere, Anyplace\n",
    "BAK=Back At Keyboard\n",
    "BBL=Be Back Later\n",
    "BBS=Be Back Soon\n",
    "BFN=Bye For Now\n",
    "B4N=Bye For Now\n",
    "BRB=Be Right Back\n",
    "BRT=Be Right There\n",
    "BTW=By The Way\n",
    "B4=Before\n",
    "B4N=Bye For Now\n",
    "CU=See You\n",
    "CUL8R=See You Later\n",
    "CYA=See You\n",
    "FAQ=Frequently Asked Questions\n",
    "FC=Fingers Crossed\n",
    "FWIW=For What It's Worth\n",
    "FYI=For Your Information\n",
    "GAL=Get A Life\n",
    "GG=Good Game\n",
    "GN=Good Night\n",
    "GMTA=Great Minds Think Alike\n",
    "GR8=Great!\n",
    "G9=Genius\n",
    "IC=I See\n",
    "ICQ=I Seek you (also a chat program)\n",
    "ILU=ILU: I Love You\n",
    "IMHO=In My Honest/Humble Opinion\n",
    "IMO=In My Opinion\n",
    "IOW=In Other Words\n",
    "IRL=In Real Life\n",
    "KISS=Keep It Simple, Stupid\n",
    "LDR=Long Distance Relationship\n",
    "LMAO=Laugh My A.. Off\n",
    "LOL=Laughing Out Loud\n",
    "LTNS=Long Time No See\n",
    "L8R=Later\n",
    "MTE=My Thoughts Exactly\n",
    "M8=Mate\n",
    "NRN=No Reply Necessary\n",
    "OIC=Oh I See\n",
    "PITA=Pain In The A..\n",
    "PRT=Party\n",
    "PRW=Parents Are Watching\n",
    "ROFL=Rolling On The Floor Laughing\n",
    "ROFLOL=Rolling On The Floor Laughing Out Loud\n",
    "ROTFLMAO=Rolling On The Floor Laughing My A.. Off\n",
    "SK8=Skate\n",
    "STATS=Your sex and age\n",
    "ASL=Age, Sex, Location\n",
    "THX=Thank You\n",
    "TTFN=Ta-Ta For Now!\n",
    "TTYL=Talk To You Later\n",
    "U=You\n",
    "U2=You Too\n",
    "U4E=Yours For Ever\n",
    "WB=Welcome Back\n",
    "WTF=What The F...\n",
    "WTG=Way To Go!\n",
    "WUF=Where Are You From?\n",
    "W8=Wait...\n",
    "7K=Sick:-D Laugher\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f3512e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_words_map_dict = {}\n",
    "chat_words_list = []\n",
    "for line in chat_words_str.split(\"\\n\"):\n",
    "    if line != \"\":\n",
    "        cw = line.split(\"=\")[0]\n",
    "        cw_expanded = line.split(\"=\")[1]\n",
    "        chat_words_list.append(cw)\n",
    "        chat_words_map_dict[cw] = cw_expanded\n",
    "chat_words_list = set(chat_words_list)\n",
    "\n",
    "def chat_words_conversion(text):\n",
    "    new_text = []\n",
    "    for w in text.split():\n",
    "        if w.upper() in chat_words_list:\n",
    "            new_text.append(chat_words_map_dict[w.upper()])\n",
    "        else:\n",
    "            new_text.append(w)\n",
    "    return \" \".join(new_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c7f6b7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'one minute Be Right Back'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_conversion(\"one minute BRB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c059004d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In My Opinion this is awesome'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_words_conversion(\"imo this is awesome\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8854fcd3",
   "metadata": {},
   "source": [
    "## 10. Spelling Correction\n",
    "\n",
    "One another important text preprocessing step is spelling correction. Typos are common in text data and we might want to correct those spelling mistakes before we do our analysis.\n",
    "\n",
    "If we are interested in wrinting a spell corrector of our own, we can probably start with famous code from Peter Norvig.\n",
    "\n",
    "In this notebook, let us use the python package pyspellchecker for our spelling correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4553bfc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspellchecker\n",
      "  Downloading pyspellchecker-0.6.3-py3-none-any.whl (2.7 MB)\n",
      "Installing collected packages: pyspellchecker\n",
      "Successfully installed pyspellchecker-0.6.3\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "1dba5b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from spellchecker import SpellChecker\n",
    "\n",
    "spell = SpellChecker()\n",
    "def correct_spellings(text):\n",
    "    corrected_text = []\n",
    "    misspelled_words = spell.unknown(text.split())\n",
    "    for word in text.split():\n",
    "        if word in misspelled_words:\n",
    "            corrected_text.append(spell.correction(word))\n",
    "        else:\n",
    "            corrected_text.append(word)\n",
    "    return \" \".join(corrected_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4b630304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spelling correcting'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"speling correctin\"\n",
    "\n",
    "correct_spellings(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7d628117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thanks for reading the notebook'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = \"thnks for readin the notebook\"\n",
    "\n",
    "correct_spellings(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78908e98",
   "metadata": {},
   "source": [
    "## Build Basic function for text preprocessing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e61f196d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def text_preprocesing(text):\n",
    "    \n",
    "    # 1. Lowercase\n",
    "    text = text.lower()\n",
    "    \n",
    "    # 2. Tokenizse\n",
    "    text = nltk.word_tokenize(text)\n",
    "    \n",
    "    list = []   # since text is already tokenized and lowercase , below code will remove special chars and store into list\n",
    "    \n",
    "    # 3. Remove special words\n",
    "    for i in text :\n",
    "        if i.isalnum():\n",
    "            list.append(i)\n",
    "       \n",
    "    text = list[:] # since list is filled with text with no special chars and lowez and tokz it will again clone to text\n",
    "    list.clear()   # and it will be clear to append new tranformed text with no stopword and puncts\n",
    "    \n",
    "    # 4. Remove stopwords and puncts\n",
    "    \n",
    "    from nltk.corpus import stopwords\n",
    "    import string\n",
    "    \n",
    "    for i in text:\n",
    "        if i  not in stopwords.words('english') and i not in string.punctuation:\n",
    "            list.append(i)\n",
    "     \n",
    "    text = list[:] # again same , list is filled with text with no special chars with no stopword and puncts and lowez and tokz it will again clone to text\n",
    "    list.clear() # and it will be clear to append new tranformed text with stemmed words\n",
    "    \n",
    "    # 5. stemming\n",
    "    \n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    ps = PorterStemmer()\n",
    "    \n",
    "    for i in text:\n",
    "        list.append(ps.stem(i))\n",
    "    \n",
    "    \n",
    "    return \" \".join(list)\n",
    "    \n",
    "         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a00f5d0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'asap run shop'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_preprocesing(\"@ASAP ; i AM  running from the Shopping\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8d8597",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
